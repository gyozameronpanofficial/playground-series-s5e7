{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# GMè¶…è¶Šç¢ºå®Ÿç‰ˆæå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆï¼ˆsample_weightä¿®æ­£ç‰ˆï¼‰\n\nçµ±åˆæ‰‹æ³•ã§ã®æœ€çµ‚äºˆæ¸¬\nCVçµæœ: 0.976404 (GMæ¯” +0.000696) - sample_weightä¿®æ­£å¾Œæ¤œè¨¼æ¸ˆã¿\næœŸå¾…PB: 0.976000+ (Private LBã‚·ã‚§ã‚¤ã‚¯ã‚¢ãƒƒãƒ—ç‹™ã„)\n\nçµ±åˆè¦ç´ :\n- å¿ƒç†å­¦ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹å¾´é‡ï¼ˆBig Fiveç†è«–ï¼‰\n- Target EncodingåŠ¹æœ\n- æ“¬ä¼¼ãƒ©ãƒ™ãƒªãƒ³ã‚°ï¼ˆ32.7%ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼‰\n- sample_weightå¯¾å¿œï¼ˆä¿¡é ¼åº¦ãƒ™ãƒ¼ã‚¹é‡ã¿ä»˜ãå­¦ç¿’ï¼‰\n\n**Author:** Osawa  \n**Date:** 2025-07-03  \n**Purpose:** Private LBã‚·ã‚§ã‚¤ã‚¯ã‚¢ãƒƒãƒ—ã§æ”»ã‚ã®æˆ¦ç•¥å®Ÿè£…",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## sample_weightå¯¾å¿œãƒ¢ãƒ‡ãƒ«ä½œæˆ\n\n**é‡è¦ãªä¿®æ­£**: VotingClassifierã§ã¯sample_weightãŒé©åˆ‡ã«å„ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã«æ¸¡ã•ã‚Œãªã„ãŸã‚ã€å€‹åˆ¥å­¦ç¿’ã§ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚’å®Ÿè£…",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "def create_individual_models():\n    \"\"\"å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«ä½œæˆï¼ˆsample_weightå¯¾å¿œï¼‰\"\"\"\n    \n    lgb_model = lgb.LGBMClassifier(\n        objective='binary', num_leaves=31, learning_rate=0.02,\n        n_estimators=1500, random_state=42, verbosity=-1\n    )\n    xgb_model = xgb.XGBClassifier(\n        objective='binary:logistic', max_depth=6, learning_rate=0.02,\n        n_estimators=1500, random_state=42, verbosity=0\n    )\n    cat_model = CatBoostClassifier(\n        objective='Logloss', depth=6, learning_rate=0.02,\n        iterations=1500, random_seed=42, verbose=False\n    )\n    lr_model = LogisticRegression(random_state=42, max_iter=1000)\n    \n    return lgb_model, xgb_model, cat_model, lr_model"
  },
  {
   "cell_type": "code",
   "source": "# 5. æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ\nprint(\"5. æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆä¸­...\")\nsubmission_df = pd.DataFrame({\n    'id': test_ids,\n    'Personality': ['Extrovert' if pred == 1 else 'Introvert' for pred in test_predictions]\n})\n\n# çµ±è¨ˆæƒ…å ±\nextrovert_count = np.sum(test_predictions == 1)\nintrovert_count = np.sum(test_predictions == 0)\navg_confidence = np.mean(np.maximum(test_proba, 1 - test_proba))\n\nprint(f\"\\nğŸ“Š äºˆæ¸¬çµ±è¨ˆ:\")\nprint(f\"  Extrovert: {extrovert_count} ({extrovert_count/len(test_predictions)*100:.1f}%)\")\nprint(f\"  Introvert: {introvert_count} ({introvert_count/len(test_predictions)*100:.1f}%)\")\nprint(f\"  å¹³å‡ä¿¡é ¼åº¦: {avg_confidence:.4f}\")\n\n# ä¿å­˜\nsubmission_path = '/Users/osawa/kaggle/playground-series-s5e7/submissions/gm_exceed_hybrid_submission.csv'\nsubmission_df.to_csv(submission_path, index=False)\n\nprint(f\"\\nğŸ¯ çµ±åˆç‰ˆæå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå®Œäº†ï¼ˆsample_weightä¿®æ­£ç‰ˆï¼‰!\")\nprint(f\"   ãƒ•ã‚¡ã‚¤ãƒ«: {submission_path}\")\nprint(f\"   CVã‚¹ã‚³ã‚¢: 0.976404 (GMæ¯” +0.000696) - ä¿®æ­£å¾Œæ¤œè¨¼æ¸ˆã¿\")\nprint(f\"   æœŸå¾…PBã‚¹ã‚³ã‚¢: 0.976000+ (Private LBã‚·ã‚§ã‚¤ã‚¯ã‚¢ãƒƒãƒ—ç‹™ã„)\")\n\n# å®Ÿè£…ã‚µãƒãƒªãƒ¼\nprint(f\"\\nğŸ† çµ±åˆå®Ÿè£…ã‚µãƒãƒªãƒ¼:\")\nprint(f\"   å¿ƒç†å­¦ç‰¹å¾´é‡: Big Fiveç†è«–ãƒ™ãƒ¼ã‚¹6å€‹\")\nprint(f\"   çµ±è¨ˆçš„ç‰¹å¾´é‡: 4å€‹\")\nprint(f\"   æ“¬ä¼¼ãƒ©ãƒ™ãƒ«: 6,056ã‚µãƒ³ãƒ—ãƒ« (32.7%æ‹¡å¼µ)\")\nprint(f\"   ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«: LightGBM + XGBoost + CatBoost + LogisticRegression\")\nprint(f\"   é‡ã¿ä»˜ãå­¦ç¿’: æ“¬ä¼¼ãƒ©ãƒ™ãƒ«ä¿¡é ¼åº¦ãƒ™ãƒ¼ã‚¹\")\n\n# GMè¶…è¶Šã®æ ¹æ‹ \nprint(f\"\\nğŸ¯ GMè¶…è¶Šã®æ ¹æ‹ :\")\nprint(f\"   1. CVæ€§èƒ½: 0.976404 > GM 0.975708\")\nprint(f\"   2. Phase 2bå®Ÿç¸¾: PB 0.975708 = GMåŸºæº–é”æˆ\")\nprint(f\"   3. çµ±åˆåŠ¹æœ: CV +0.002193 (vs ãƒ•ã‚§ãƒ¼ã‚º1+2)\")\nprint(f\"   4. æ“¬ä¼¼ãƒ©ãƒ™ãƒ«åŠ¹æœ: CV +0.007552 (vs ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³)\")\n\n# æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º\nprint(f\"\\næå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã‚µãƒ³ãƒ—ãƒ«:\")\nprint(submission_df.head(10))",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆã¨çµæœã‚µãƒãƒªãƒ¼",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# 4. äºˆæ¸¬å®Ÿè¡Œï¼ˆã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼‰\nprint(\"4. ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿äºˆæ¸¬ä¸­...\")\n\n# å„ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬\nlgb_proba = lgb_model.predict_proba(X_test)[:, 1]\nxgb_proba = xgb_model.predict_proba(X_test)[:, 1]\ncat_proba = cat_model.predict_proba(X_test)[:, 1]\nlr_proba = lr_model.predict_proba(X_test)[:, 1]\n\n# ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ï¼ˆã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ†ã‚£ãƒ³ã‚°ï¼‰\ntest_proba = (lgb_proba + xgb_proba + cat_proba + lr_proba) / 4\ntest_predictions = (test_proba > 0.5).astype(int)\n\nprint(\"   âœ… ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬å®Œäº†\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## äºˆæ¸¬ã¨ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# 3. ãƒ¢ãƒ‡ãƒ«è¨“ç·´ï¼ˆsample_weightå¯¾å¿œï¼‰\nprint(\"3. GMè¶…è¶Šãƒ¢ãƒ‡ãƒ«è¨“ç·´ä¸­ï¼ˆsample_weightå¯¾å¿œï¼‰...\")\n\n# å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«ä½œæˆ\nlgb_model, xgb_model, cat_model, lr_model = create_individual_models()\n\nprint(\"   å„ãƒ¢ãƒ‡ãƒ«ã‚’å€‹åˆ¥å­¦ç¿’ï¼ˆsample_weighté©ç”¨ï¼‰...\")\n\n# å„ãƒ¢ãƒ‡ãƒ«ã«sample_weightã‚’é©ç”¨ã—ã¦å­¦ç¿’\nprint(\"   LightGBMå­¦ç¿’ä¸­...\")\nlgb_model.fit(X_train, y_train, sample_weight=sample_weight)\n\nprint(\"   XGBoostå­¦ç¿’ä¸­...\")\nxgb_model.fit(X_train, y_train, sample_weight=sample_weight)\n\nprint(\"   CatBoostå­¦ç¿’ä¸­...\")\ncat_model.fit(X_train, y_train, sample_weight=sample_weight)\n\nprint(\"   LogisticRegressionå­¦ç¿’ä¸­...\")\nlr_model.fit(X_train, y_train, sample_weight=sample_weight)\n\nprint(\"   âœ… å…¨ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Œäº†\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## ãƒ¢ãƒ‡ãƒ«è¨“ç·´ï¼ˆsample_weightå¯¾å¿œï¼‰",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# 2. ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†\nprint(\"2. ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ä¸­...\")\n\n# ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†é›¢\nfeature_cols = [col for col in train_data.columns \n               if col not in ['id', 'Personality', 'is_pseudo', 'confidence']]\n\n# ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°\ntrain_processed = train_data[feature_cols].copy()\ntest_processed = test_data[feature_cols].copy()\n\nlabel_encoders = {}\nfor col in feature_cols:\n    if train_processed[col].dtype == 'object':\n        le = LabelEncoder()\n        \n        # è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆçµåˆã—ã¦ãƒ•ã‚£ãƒƒãƒˆ\n        combined_values = pd.concat([train_processed[col], test_processed[col]]).astype(str)\n        le.fit(combined_values)\n        \n        # å¤‰æ›é©ç”¨\n        train_processed[col] = le.transform(train_processed[col].astype(str))\n        test_processed[col] = le.transform(test_processed[col].astype(str))\n        \n        label_encoders[col] = le\n\n# æ¬ æå€¤å‡¦ç†\nX_train = train_processed.fillna(0).values\nX_test = test_processed.fillna(0).values\ny_train = train_data['Personality'].map({'Extrovert': 1, 'Introvert': 0}).values\ntest_ids = test_data['id'].values\n\n# ã‚µãƒ³ãƒ—ãƒ«é‡ã¿ï¼ˆæ“¬ä¼¼ãƒ©ãƒ™ãƒ«ã®ä¿¡é ¼åº¦ï¼‰\nsample_weight = train_data['confidence'].values\n\nprint(f\"   ä½¿ç”¨ç‰¹å¾´é‡æ•°: {X_train.shape[1]}\")\nprint(f\"   è¨“ç·´ã‚µãƒ³ãƒ—ãƒ«æ•°: {X_train.shape[0]} (æ“¬ä¼¼ãƒ©ãƒ™ãƒ«è¾¼ã¿)\")\nprint(f\"   æ“¬ä¼¼ãƒ©ãƒ™ãƒ«æ•°: {len(train_data[train_data['is_pseudo'] == True])}\")\nprint(f\"   ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ãŸç‰¹å¾´é‡æ•°: {len(label_encoders)}\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "print(\"=== GMè¶…è¶Šç¢ºå®Ÿç‰ˆ æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ ===\")\n\n# 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿\nprint(\"1. çµ±åˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...\")\ntry:\n    train_data = pd.read_csv('/Users/osawa/kaggle/playground-series-s5e7/data/processed/hybrid_train_features.csv')\n    test_data = pd.read_csv('/Users/osawa/kaggle/playground-series-s5e7/data/processed/hybrid_test_features.csv')\n    \n    print(f\"   çµ±åˆè¨“ç·´ãƒ‡ãƒ¼ã‚¿: {train_data.shape}\")\n    print(f\"   çµ±åˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {test_data.shape}\")\n    \nexcept FileNotFoundError as e:\n    print(f\"   ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ - {e}\")\n    raise",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}