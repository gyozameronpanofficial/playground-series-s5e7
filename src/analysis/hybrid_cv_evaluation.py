"""
çµ±åˆç‰ˆCVæ€§èƒ½è©•ä¾¡

Phase 2b + ãƒ•ã‚§ãƒ¼ã‚º1+2çµ±åˆæ‰‹æ³•ã®æ€§èƒ½è©•ä¾¡
- å¿ƒç†å­¦ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹å¾´é‡
- Target Encodingï¼ˆå®Ÿè¨¼æ¸ˆã¿æœ‰åŠ¹æ€§ï¼‰  
- æ“¬ä¼¼ãƒ©ãƒ™ãƒªãƒ³ã‚°ï¼ˆãƒ‡ãƒ¼ã‚¿æ‹¡å¼µåŠ¹æœï¼‰

æœŸå¾…: CV 0.975000+ & PB 0.976500+

Author: Osawa
Date: 2025-07-03
Purpose: GMè¶…è¶Šç¢ºå®Ÿãªçµ±åˆæ‰‹æ³•ã®æ€§èƒ½æ¤œè¨¼
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import StratifiedKFold, cross_val_score
from sklearn.ensemble import VotingClassifier
import lightgbm as lgb
import xgboost as xgb
from catboost import CatBoostClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score
import json
import warnings
warnings.filterwarnings('ignore')

def create_hybrid_ensemble():
    """çµ±åˆç‰ˆã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«"""
    
    models = [
        ('lgb', lgb.LGBMClassifier(
            objective='binary', num_leaves=31, learning_rate=0.05,
            n_estimators=500, random_state=42, verbosity=-1
        )),
        ('xgb', xgb.XGBClassifier(
            objective='binary:logistic', max_depth=6, learning_rate=0.05,
            n_estimators=500, random_state=42, verbosity=0
        )),
        ('cat', CatBoostClassifier(
            objective='Logloss', depth=6, learning_rate=0.05,
            iterations=500, random_seed=42, verbose=False
        )),
        ('lr', LogisticRegression(random_state=42, max_iter=1000))
    ]
    
    return VotingClassifier(estimators=models, voting='soft')

def evaluate_hybrid_performance():
    """çµ±åˆæ‰‹æ³•æ€§èƒ½è©•ä¾¡ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    
    print("=== çµ±åˆç‰ˆCVæ€§èƒ½è©•ä¾¡ ===")
    
    # 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print("1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
    
    try:
        # çµ±åˆãƒ‡ãƒ¼ã‚¿
        hybrid_data = pd.read_csv('/Users/osawa/kaggle/playground-series-s5e7/data/processed/hybrid_train_features.csv')
        
        # æ¯”è¼ƒç”¨ãƒ‡ãƒ¼ã‚¿
        baseline_data = pd.read_csv('/Users/osawa/kaggle/playground-series-s5e7/data/raw/train.csv')
        
        print(f"   çµ±åˆãƒ‡ãƒ¼ã‚¿: {hybrid_data.shape}")
        print(f"   ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³: {baseline_data.shape}")
        
    except FileNotFoundError as e:
        print(f"   ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ - {e}")
        return None
    
    # 2. ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
    print("2. ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ä¸­...")
    
    # çµ±åˆãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
    feature_cols_hybrid = [col for col in hybrid_data.columns 
                          if col not in ['id', 'Personality', 'is_pseudo', 'confidence']]
    
    # æ“¬ä¼¼ãƒ©ãƒ™ãƒ«è¾¼ã¿ãƒ‡ãƒ¼ã‚¿ã¨å…ƒãƒ‡ãƒ¼ã‚¿ã®ã¿ã®åˆ†é›¢
    original_mask = hybrid_data['is_pseudo'] == False
    original_data = hybrid_data[original_mask].copy()
    
    print(f"   å…ƒãƒ‡ãƒ¼ã‚¿ã®ã¿: {original_data.shape[0]}ã‚µãƒ³ãƒ—ãƒ«")
    print(f"   æ“¬ä¼¼ãƒ©ãƒ™ãƒ«è¾¼ã¿: {hybrid_data.shape[0]}ã‚µãƒ³ãƒ—ãƒ«")
    print(f"   æ“¬ä¼¼ãƒ©ãƒ™ãƒ«æ•°: {hybrid_data.shape[0] - original_data.shape[0]}ã‚µãƒ³ãƒ—ãƒ«")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™
    datasets = {
        'hybrid_with_pseudo': hybrid_data,
        'hybrid_original_only': original_data,
        'baseline': baseline_data
    }
    
    results = {}
    
    for name, data in datasets.items():
        print(f"\\n   {name}ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ä¸­...")
        
        if name == 'baseline':
            feature_cols = [col for col in data.columns if col not in ['id', 'Personality']]
        else:
            feature_cols = feature_cols_hybrid
        
        X = data[feature_cols].copy()
        
        # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
        for col in X.columns:
            if X[col].dtype == 'object':
                le = LabelEncoder()
                X[col] = le.fit_transform(X[col].astype(str))
        
        X = X.fillna(0).values
        y = data['Personality'].map({'Extrovert': 1, 'Introvert': 0}).values
        
        # ã‚µãƒ³ãƒ—ãƒ«é‡ã¿ï¼ˆæ“¬ä¼¼ãƒ©ãƒ™ãƒ«ã®å ´åˆï¼‰
        if 'confidence' in data.columns:
            sample_weight = data['confidence'].values
        else:
            sample_weight = None
        
        results[name] = {
            'X': X,
            'y': y,
            'sample_weight': sample_weight,
            'feature_count': X.shape[1]
        }
        
        print(f"     ç‰¹å¾´é‡æ•°: {X.shape[1]}, ã‚µãƒ³ãƒ—ãƒ«æ•°: {X.shape[0]}")
    
    # 3. CVè©•ä¾¡
    print("\\n3. ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³è©•ä¾¡ä¸­...")
    
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    cv_results = {}
    
    for name, data_info in results.items():
        print(f"   {name}è©•ä¾¡ä¸­...")
        model = create_hybrid_ensemble()
        
        if data_info['sample_weight'] is not None:
            # é‡ã¿ä»˜ãCVï¼ˆæ‰‹å‹•å®Ÿè£…ãŒå¿…è¦ï¼‰
            cv_scores = []
            X, y = data_info['X'], data_info['y']
            
            for train_idx, valid_idx in cv.split(X, y):
                X_train, X_valid = X[train_idx], X[valid_idx]
                y_train, y_valid = y[train_idx], y[valid_idx]
                
                model_copy = create_hybrid_ensemble()
                model_copy.fit(X_train, y_train)
                valid_pred = model_copy.predict(X_valid)
                score = accuracy_score(y_valid, valid_pred)
                cv_scores.append(score)
            
            cv_scores = np.array(cv_scores)
        else:
            # é€šå¸¸ã®CV
            cv_scores = cross_val_score(model, data_info['X'], data_info['y'], 
                                      cv=cv, scoring='accuracy', n_jobs=-1)
        
        cv_results[name] = {
            'scores': cv_scores,
            'mean': cv_scores.mean(),
            'std': cv_scores.std(),
            'feature_count': data_info['feature_count']
        }
    
    # 4. çµæœåˆ†æ
    print("\\n4. çµæœåˆ†æ")
    print("=" * 70)
    
    # å„æ‰‹æ³•ã®çµæœè¡¨ç¤º
    for name, result in cv_results.items():
        print(f"\\nã€{name}ã€‘")
        print(f"   å¹³å‡CVã‚¹ã‚³ã‚¢: {result['mean']:.6f} Â± {result['std']:.6f}")
        print(f"   å€‹åˆ¥ã‚¹ã‚³ã‚¢: {[f'{score:.6f}' for score in result['scores']]}")
        print(f"   ç‰¹å¾´é‡æ•°: {result['feature_count']}")
    
    # æ”¹å–„åŠ¹æœåˆ†æ
    print(f"\\nğŸ“Š æ”¹å–„åŠ¹æœåˆ†æ")
    print("-" * 50)
    
    baseline_score = cv_results['baseline']['mean']
    hybrid_original_score = cv_results['hybrid_original_only']['mean']
    hybrid_pseudo_score = cv_results['hybrid_with_pseudo']['mean']
    
    print(f"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³: {baseline_score:.6f}")
    print(f"çµ±åˆç‰ˆï¼ˆå…ƒãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰: {hybrid_original_score:.6f} ({hybrid_original_score - baseline_score:+.6f})")
    print(f"çµ±åˆç‰ˆï¼ˆæ“¬ä¼¼ãƒ©ãƒ™ãƒ«è¾¼ã¿ï¼‰: {hybrid_pseudo_score:.6f} ({hybrid_pseudo_score - baseline_score:+.6f})")
    
    # GMæ¯”è¼ƒ
    gm_baseline = 0.975708
    print(f"\\nğŸ¯ GMãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒ")
    print("-" * 40)
    print(f"GMã‚¹ã‚³ã‚¢: {gm_baseline:.6f}")
    
    for name, result in cv_results.items():
        score = result['mean']
        diff = score - gm_baseline
        status = "âœ… è¶…è¶Š" if diff > 0 else "âš ï¸ æœªé”"
        print(f"{name}: {score:.6f} ({diff:+.6f}) {status}")
    
    # æœ€é«˜æ€§èƒ½ç¢ºèª
    best_method = max(cv_results.keys(), key=lambda x: cv_results[x]['mean'])
    best_score = cv_results[best_method]['mean']
    
    print(f"\\nğŸ† æœ€é«˜æ€§èƒ½")
    print(f"æ‰‹æ³•: {best_method}")
    print(f"CVã‚¹ã‚³ã‚¢: {best_score:.6f}")
    
    if best_score > gm_baseline:
        print(f"âœ… GMè¶…è¶Šé”æˆ! å·®åˆ†: {best_score - gm_baseline:+.6f}")
        status = "gm_exceeded"
    else:
        print(f"âŒ GMæœªé”ã€‚ä¸è¶³åˆ†: {gm_baseline - best_score:.6f}")
        status = "gm_not_reached"
    
    # 5. éå»å®Ÿè£…æ¯”è¼ƒ
    print(f"\\nğŸ“ˆ éå»å®Ÿè£…æ¯”è¼ƒ")
    print("-" * 40)
    
    past_results = {
        'ãƒ•ã‚§ãƒ¼ã‚º1+2': 0.974211,
        'Phase 2a': 0.968851,
        'Phase 2b': 0.968905
    }
    
    for past_name, past_score in past_results.items():
        current_score = cv_results['hybrid_with_pseudo']['mean']
        diff = current_score - past_score
        print(f"{past_name}: {past_score:.6f} â†’ çµ±åˆç‰ˆ: {current_score:.6f} ({diff:+.6f})")
    
    # 6. çµæœä¿å­˜
    print("\\n5. çµæœä¿å­˜ä¸­...")
    
    save_results = {
        'hybrid_with_pseudo_cv_mean': cv_results['hybrid_with_pseudo']['mean'],
        'hybrid_with_pseudo_cv_std': cv_results['hybrid_with_pseudo']['std'],
        'hybrid_original_only_cv_mean': cv_results['hybrid_original_only']['mean'],
        'hybrid_original_only_cv_std': cv_results['hybrid_original_only']['std'],
        'baseline_cv_mean': cv_results['baseline']['mean'],
        'baseline_cv_std': cv_results['baseline']['std'],
        'best_method': best_method,
        'best_score': best_score,
        'gm_baseline': gm_baseline,
        'gm_status': status,
        'gm_diff': best_score - gm_baseline,
        'cv_scores_details': {name: result['scores'].tolist() for name, result in cv_results.items()},
        'feature_counts': {name: result['feature_count'] for name, result in cv_results.items()}
    }
    
    results_path = '/Users/osawa/kaggle/playground-series-s5e7/data/processed/hybrid_cv_results.json'
    with open(results_path, 'w') as f:
        json.dump(save_results, f, indent=2)
    
    print(f"   çµæœä¿å­˜å®Œäº†: {results_path}")
    
    print(f"\\n" + "="*70)
    print("çµ±åˆç‰ˆCVè©•ä¾¡å®Œäº†")
    print("="*70)
    
    return save_results

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    
    results = evaluate_hybrid_performance()
    
    if results:
        if results['gm_status'] == 'gm_exceeded':
            print("ğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: GMè¶…è¶Šç¢ºå®Ÿï¼çµ±åˆç‰ˆæå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ")
        else:
            print("ğŸ“‹ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: æ›´ãªã‚‹æ”¹å–„ç­–æ¤œè¨ã¾ãŸã¯ãƒ™ã‚¹ãƒˆæ‰‹æ³•ã§ã®æå‡º")
    
    return results

if __name__ == "__main__":
    main()