"""
Phase 2b: é«˜åº¦Target Encodingå®Ÿè£…

Phase 2aã®TF-IDFå¤±æ•—ã‚’å—ã‘ã¦ã€ã‚ˆã‚Šã‚·ãƒ³ãƒ—ãƒ«ã§åŠ¹æœçš„ãªTarget Encodingã«æ³¨åŠ›
- Smoothing Target Encodingï¼ˆãƒ™ã‚¤ã‚ºå¹³å‡ï¼‰
- è¤‡æ•°CVæˆ¦ç•¥ã§ã®é ‘å¥æ€§å‘ä¸Š
- ãƒã‚¤ã‚ºæ³¨å…¥ã«ã‚ˆã‚‹æ±åŒ–æ€§èƒ½å‘ä¸Š

Author: Osawa
Date: 2025-07-03
Purpose: GMè¶…è¶Šã®ãŸã‚ã®é«˜å“è³ªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import KFold, StratifiedKFold
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import VotingClassifier
import lightgbm as lgb
import xgboost as xgb
from catboost import CatBoostClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import warnings
warnings.filterwarnings('ignore')

class AdvancedTargetEncoder:
    """é«˜åº¦Target Encodingã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self, smoothing_alpha=100, n_splits=5, random_state=42):
        self.smoothing_alpha = smoothing_alpha
        self.n_splits = n_splits
        self.random_state = random_state
        self.target_encoders = {}
        self.global_mean = None
        
    def smooth_target_encoding(self, feature_series, target_series, alpha=None):
        """
        Smoothing Target Encodingã®å®Ÿè£…
        
        Parameters:
        -----------
        feature_series : pd.Series
            ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å¯¾è±¡ã®ç‰¹å¾´é‡
        target_series : pd.Series
            ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°
        alpha : float
            å¹³æ»‘åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆå¤§ãã„ã»ã©ä¿å®ˆçš„ï¼‰
        
        Returns:
        --------
        dict : ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å€¤
        """
        if alpha is None:
            alpha = self.smoothing_alpha
        
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¹³å‡
        global_mean = target_series.mean()
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆè¨ˆç®—
        stats_df = pd.DataFrame({
            'feature': feature_series,
            'target': target_series
        })
        
        category_stats = stats_df.groupby('feature').agg({
            'target': ['count', 'mean']
        }).reset_index()
        
        category_stats.columns = ['category', 'count', 'mean']
        
        # Smoothing Target Encodingè¨ˆç®—
        # smoothed_mean = (count * mean + alpha * global_mean) / (count + alpha)
        category_stats['smoothed_mean'] = (
            category_stats['count'] * category_stats['mean'] + 
            alpha * global_mean
        ) / (category_stats['count'] + alpha)
        
        # è¾æ›¸å½¢å¼ã§è¿”ã™
        encoding_dict = dict(zip(category_stats['category'], category_stats['smoothed_mean']))
        
        return encoding_dict, global_mean
    
    def create_cv_target_encoding(self, X, y, feature_name, cv_strategy='stratified'):
        """
        ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å†…ã§ã®Target Encoding
        
        Parameters:
        -----------
        X : pd.DataFrame
            ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        y : pd.Series
            ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°
        feature_name : str
            ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å¯¾è±¡ã®ç‰¹å¾´é‡å
        cv_strategy : str
            CVæˆ¦ç•¥ï¼ˆ'stratified' or 'kfold'ï¼‰
        
        Returns:
        --------
        pd.Series : ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æ¸ˆã¿ç‰¹å¾´é‡
        """
        
        # CVè¨­å®š
        if cv_strategy == 'stratified':
            cv = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=self.random_state)
        else:
            cv = KFold(n_splits=self.n_splits, shuffle=True, random_state=self.random_state)
        
        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰çµæœã‚’æ ¼ç´ã™ã‚‹é…åˆ—
        encoded_feature = np.zeros(len(X))
        
        # CVå†…ã§ã®Target Encoding
        for train_idx, valid_idx in cv.split(X, y):
            # Train foldå†…ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰è¾æ›¸ã‚’ä½œæˆ
            train_feature = X.iloc[train_idx][feature_name]
            train_target = y.iloc[train_idx]
            
            encoding_dict, global_mean = self.smooth_target_encoding(
                train_feature, train_target
            )
            
            # Valid foldã«é©ç”¨
            valid_feature = X.iloc[valid_idx][feature_name]
            
            # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰é©ç”¨ï¼ˆæœªçŸ¥ã‚«ãƒ†ã‚´ãƒªã¯ã‚°ãƒ­ãƒ¼ãƒãƒ«å¹³å‡ï¼‰
            encoded_valid = valid_feature.map(encoding_dict).fillna(global_mean)
            encoded_feature[valid_idx] = encoded_valid
        
        return pd.Series(encoded_feature, index=X.index, name=f'{feature_name}_target_encoded')
    
    def create_noise_augmented_encoding(self, X, y, feature_name, noise_level=0.01):
        """
        ãƒã‚¤ã‚ºæ³¨å…¥ã«ã‚ˆã‚‹Target Encodingã®é ‘å¥æ€§å‘ä¸Š
        
        Parameters:
        -----------
        X : pd.DataFrame
            ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        y : pd.Series
            ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°
        feature_name : str
            ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å¯¾è±¡ã®ç‰¹å¾´é‡å
        noise_level : float
            ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ï¼ˆæ¨™æº–åå·®ï¼‰
        
        Returns:
        --------
        pd.Series : ãƒã‚¤ã‚ºæ³¨å…¥æ¸ˆã¿ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ç‰¹å¾´é‡
        """
        
        # åŸºæœ¬ã®Target Encoding
        base_encoded = self.create_cv_target_encoding(X, y, feature_name)
        
        # ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒã‚¤ã‚ºæ³¨å…¥
        noise = np.random.normal(0, noise_level, len(base_encoded))
        noise_encoded = base_encoded + noise
        
        return pd.Series(noise_encoded, index=X.index, name=f'{feature_name}_noise_encoded')
    
    def create_multiple_cv_encodings(self, X, y, feature_name, n_encodings=3):
        """
        è¤‡æ•°ã®ç•°ãªã‚‹CVè¨­å®šã§ã®Target Encodingã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«
        
        Parameters:
        -----------
        X : pd.DataFrame
            ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        y : pd.Series
            ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°
        feature_name : str
            ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å¯¾è±¡ã®ç‰¹å¾´é‡å
        n_encodings : int
            ä½œæˆã™ã‚‹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æ•°
        
        Returns:
        --------
        pd.DataFrame : è¤‡æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ç‰¹å¾´é‡
        """
        
        encodings = []
        
        for i in range(n_encodings):
            # ç•°ãªã‚‹ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ã§CVè¨­å®š
            encoder = AdvancedTargetEncoder(
                smoothing_alpha=self.smoothing_alpha,
                n_splits=self.n_splits,
                random_state=self.random_state + i
            )
            
            # CVæˆ¦ç•¥ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠ
            cv_strategy = 'stratified' if i % 2 == 0 else 'kfold'
            
            encoded = encoder.create_cv_target_encoding(X, y, feature_name, cv_strategy)
            encoded.name = f'{feature_name}_cv_encoded_{i+1}'
            encodings.append(encoded)
        
        return pd.concat(encodings, axis=1)
    
    def fit_transform(self, X, y, categorical_features=None):
        """
        å…¨ç‰¹å¾´é‡ã«å¯¾ã™ã‚‹Target Encodingã®é©ç”¨
        
        Parameters:
        -----------
        X : pd.DataFrame
            ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        y : pd.Series
            ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°
        categorical_features : list
            ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡ã®ãƒªã‚¹ãƒˆ
        
        Returns:
        --------
        pd.DataFrame : Target Encodingé©ç”¨æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿
        """
        
        print("=== é«˜åº¦Target Encodingå®Ÿè¡Œ ===")
        
        # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡ã®è‡ªå‹•æ¤œå‡º
        if categorical_features is None:
            categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()
        
        print(f"å¯¾è±¡ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡: {categorical_features}")
        
        # çµæœã‚’æ ¼ç´ã™ã‚‹DataFrame
        encoded_X = X.copy()
        
        for feature in categorical_features:
            print(f"\n{feature}ã®Target Encodingä¸­...")
            
            # 1. åŸºæœ¬ã®Smoothing Target Encoding
            basic_encoded = self.create_cv_target_encoding(encoded_X, y, feature)
            encoded_X[f'{feature}_basic_encoded'] = basic_encoded
            
            # 2. ãƒã‚¤ã‚ºæ³¨å…¥ç‰ˆ
            noise_encoded = self.create_noise_augmented_encoding(encoded_X, y, feature)
            encoded_X[f'{feature}_noise_encoded'] = noise_encoded
            
            # 3. è¤‡æ•°CVç‰ˆï¼ˆ2å€‹ï¼‰
            multi_cv_encoded = self.create_multiple_cv_encodings(encoded_X, y, feature, n_encodings=2)
            encoded_X = pd.concat([encoded_X, multi_cv_encoded], axis=1)
            
            print(f"  ç”Ÿæˆç‰¹å¾´é‡æ•°: {4}å€‹")
        
        print(f"\nå…ƒç‰¹å¾´é‡æ•°: {X.shape[1]} â†’ æ‹¡å¼µå¾Œ: {encoded_X.shape[1]}")
        
        return encoded_X
    
    def transform(self, X_test):
        """
        ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¸ã®Target Encodingã®é©ç”¨
        
        Parameters:
        -----------
        X_test : pd.DataFrame
            ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        
        Returns:
        --------
        pd.DataFrame : ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æ¸ˆã¿ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        """
        
        # å®Ÿè£…ã®ç°¡ç•¥åŒ–ã®ãŸã‚ã€fit_transformã§ä¿å­˜ã—ãŸè¾æ›¸ã‚’ä½¿ç”¨
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€fitæ™‚ã«è¾æ›¸ã‚’ä¿å­˜ã—ã€transformã§é©ç”¨
        print("è­¦å‘Š: transformãƒ¡ã‚½ãƒƒãƒ‰ã¯ç°¡ç•¥å®Ÿè£…ã§ã™")
        return X_test

def create_phase2b_features():
    """Phase 2bç”¨ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ"""
    
    print("=== Phase 2b ç‰¹å¾´é‡ä½œæˆé–‹å§‹ ===")
    
    # 1. å…ƒãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print("1. å…ƒãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
    train_data = pd.read_csv('/Users/osawa/kaggle/playground-series-s5e7/data/raw/train.csv')
    test_data = pd.read_csv('/Users/osawa/kaggle/playground-series-s5e7/data/raw/test.csv')
    
    print(f"   è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {train_data.shape}")
    print(f"   ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {test_data.shape}")
    
    # 2. Target Encodingã®é©ç”¨
    print("\n2. Target Encodingé©ç”¨ä¸­...")
    
    # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†é›¢
    feature_cols = [col for col in train_data.columns if col not in ['id', 'Personality']]
    X_train = train_data[feature_cols]
    y_train = train_data['Personality'].map({'Extrovert': 1, 'Introvert': 0})
    X_test = test_data[feature_cols]
    
    # Target Encoderã®åˆæœŸåŒ–
    target_encoder = AdvancedTargetEncoder(
        smoothing_alpha=50,  # ã‚ˆã‚Šä¿å®ˆçš„ãªå€¤
        n_splits=5,
        random_state=42
    )
    
    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¸ã®Target Encodingé©ç”¨
    X_train_encoded = target_encoder.fit_transform(X_train, y_train)
    
    # 3. ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç°¡æ˜“å‡¦ç†
    print("\n3. ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å‡¦ç†ä¸­...")
    
    # ç°¡æ˜“å®Ÿè£…ï¼šè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å€¤ã®å¹³å‡ã‚’ä½¿ç”¨
    X_test_encoded = X_test.copy()
    
    # å„ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡ã«ã¤ã„ã¦
    categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()
    
    for feature in categorical_features:
        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å€¤ã‹ã‚‰çµ±è¨ˆã‚’è¨ˆç®—
        encoded_cols = [col for col in X_train_encoded.columns if col.startswith(f'{feature}_') and 'encoded' in col]
        
        for encoded_col in encoded_cols:
            # å„ã‚«ãƒ†ã‚´ãƒªã®å¹³å‡ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å€¤ã‚’è¨ˆç®—
            encoding_dict = X_train_encoded.groupby(X_train[feature])[encoded_col].mean().to_dict()
            global_mean = X_train_encoded[encoded_col].mean()
            
            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«é©ç”¨
            X_test_encoded[encoded_col] = X_test[feature].map(encoding_dict).fillna(global_mean)
    
    # 4. æœ€çµ‚ãƒ‡ãƒ¼ã‚¿ä½œæˆ
    print("\n4. æœ€çµ‚ãƒ‡ãƒ¼ã‚¿ä½œæˆä¸­...")
    
    # idåˆ—ã¨Personalityåˆ—ã‚’è¿½åŠ 
    train_final = pd.concat([
        train_data[['id', 'Personality']], 
        X_train_encoded
    ], axis=1)
    
    test_final = pd.concat([
        test_data[['id']],
        X_test_encoded
    ], axis=1)
    
    # 5. ä¿å­˜
    print("\n5. ãƒ‡ãƒ¼ã‚¿ä¿å­˜ä¸­...")
    train_path = '/Users/osawa/kaggle/playground-series-s5e7/data/processed/phase2b_train_features.csv'
    test_path = '/Users/osawa/kaggle/playground-series-s5e7/data/processed/phase2b_test_features.csv'
    
    train_final.to_csv(train_path, index=False)
    test_final.to_csv(test_path, index=False)
    
    print(f"âœ… Phase 2bç‰¹å¾´é‡ä½œæˆå®Œäº†")
    print(f"   è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {train_final.shape} â†’ {train_path}")
    print(f"   ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {test_final.shape} â†’ {test_path}")
    
    # 6. ç‰¹å¾´é‡çµ±è¨ˆ
    print(f"\nğŸ“Š ç‰¹å¾´é‡çµ±è¨ˆ:")
    print(f"   å…ƒç‰¹å¾´é‡æ•°: {len(feature_cols)}")
    print(f"   æ‹¡å¼µå¾Œç‰¹å¾´é‡æ•°: {train_final.shape[1] - 2}")  # id, Personalityã‚’é™¤ã
    print(f"   è¿½åŠ ç‰¹å¾´é‡æ•°: {train_final.shape[1] - 2 - len(feature_cols)}")
    
    return train_final, test_final

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    
    # Phase 2bç‰¹å¾´é‡ä½œæˆ
    train_data, test_data = create_phase2b_features()
    
    print(f"\n" + "="*50)
    print("Phase 2b Target Encodingå®Ÿè£…å®Œäº†")
    print("="*50)
    print("ğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: CVè©•ä¾¡ã¨Submissionä½œæˆ")
    
    return train_data, test_data

if __name__ == "__main__":
    main()