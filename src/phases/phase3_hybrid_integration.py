"""
Phase 2b + ãƒ•ã‚§ãƒ¼ã‚º1+2 çµ±åˆå®Ÿè£…

Phase 2bã®æˆåŠŸï¼ˆPB 0.975708 = GMåŸºæº–é”æˆï¼‰ã‚’è¸ã¾ãˆã€
ãƒ•ã‚§ãƒ¼ã‚º1+2ã®å¿ƒç†å­¦ç‰¹å¾´é‡+æ“¬ä¼¼ãƒ©ãƒ™ãƒªãƒ³ã‚°ï¼ˆCV 0.974211ï¼‰ã¨çµ±åˆ
GMè¶…è¶Šã‚’ç¢ºå®Ÿã«ã™ã‚‹çµ±åˆæ‰‹æ³•ã®å®Ÿè£…

çµ±åˆè¦ç´ :
1. å¿ƒç†å­¦ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹å¾´é‡ï¼ˆBig Fiveç†è«–ãƒ™ãƒ¼ã‚¹ï¼‰
2. Target Encodingï¼ˆå®Ÿè¨¼æ¸ˆã¿æœ‰åŠ¹æ€§ï¼‰
3. æ“¬ä¼¼ãƒ©ãƒ™ãƒªãƒ³ã‚°ï¼ˆãƒ‡ãƒ¼ã‚¿æ‹¡å¼µåŠ¹æœï¼‰

æœŸå¾…åŠ¹æœ: CV 0.975000+ & PB 0.976500+

Author: Osawa
Date: 2025-07-03
Purpose: GMè¶…è¶Šç¢ºå®Ÿãªçµ±åˆæ‰‹æ³•ã®å®Ÿè£…
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import VotingClassifier
import lightgbm as lgb
import xgboost as xgb
from catboost import CatBoostClassifier
from sklearn.linear_model import LogisticRegression
import warnings
warnings.filterwarnings('ignore')

class HybridFeatureEngineer:
    """çµ±åˆç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢"""
    
    def __init__(self, random_state=42):
        self.random_state = random_state
        self.target_encoders = {}
        
    def create_psychological_features(self, df):
        """å¿ƒç†å­¦ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹å¾´é‡ã®ä½œæˆï¼ˆãƒ•ã‚§ãƒ¼ã‚º1ã‹ã‚‰ï¼‰"""
        
        print("   å¿ƒç†å­¦ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹å¾´é‡ä½œæˆä¸­...")
        
        # Big Fiveç†è«–ãƒ™ãƒ¼ã‚¹ã‚¹ã‚³ã‚¢
        extroversion_features = ['Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency']
        introversion_features = ['Time_spent_Alone', 'Stage_fear', 'Drained_after_socializing']
        
        # æ•°å€¤åŒ–é–¢æ•°
        def convert_to_numeric(series):
            if series.dtype == 'object':
                mapping = {'No': 0, 'Sometimes': 1, 'Yes': 2}
                if series.name in ['Friends_circle_size', 'Post_frequency']:
                    mapping = {'Small/Low': 0, 'Medium': 1, 'Large/High': 2}
                return series.map(mapping).fillna(1)
            return series
        
        df_processed = df.copy()
        
        # å…¨ç‰¹å¾´é‡ã‚’æ•°å€¤åŒ–
        for col in df_processed.columns:
            if col not in ['id', 'Personality']:
                df_processed[col] = convert_to_numeric(df_processed[col])
        
        # å¤–å‘æ€§ã‚¹ã‚³ã‚¢
        extroversion_cols = [col for col in extroversion_features if col in df_processed.columns]
        df_processed['extroversion_score'] = df_processed[extroversion_cols].mean(axis=1)
        
        # å†…å‘æ€§ã‚¹ã‚³ã‚¢
        introversion_cols = [col for col in introversion_features if col in df_processed.columns]
        df_processed['introversion_score'] = df_processed[introversion_cols].mean(axis=1)
        
        # ç¤¾äº¤ãƒãƒ©ãƒ³ã‚¹
        df_processed['social_balance'] = df_processed['extroversion_score'] - df_processed['introversion_score']
        
        # ç¤¾äº¤ç–²åŠ´åº¦
        if 'Drained_after_socializing' in df_processed.columns and 'Social_event_attendance' in df_processed.columns:
            df_processed['social_fatigue'] = df_processed['Drained_after_socializing'] * df_processed['Social_event_attendance']
        
        # ç¤¾äº¤ç©æ¥µåº¦
        if 'Going_outside' in df_processed.columns and 'Friends_circle_size' in df_processed.columns:
            df_processed['social_proactivity'] = df_processed['Going_outside'] * df_processed['Friends_circle_size']
        
        # å­¤ç‹¬å—œå¥½åº¦
        if 'Time_spent_Alone' in df_processed.columns and 'Stage_fear' in df_processed.columns:
            df_processed['solitude_preference'] = df_processed['Time_spent_Alone'] * (2 - df_processed['Stage_fear'])
        
        print(f"     å¿ƒç†å­¦ç‰¹å¾´é‡è¿½åŠ æ•°: 6å€‹")
        return df_processed
    
    def apply_target_encoding(self, train_df, test_df, target_col='Personality'):
        """Target Encodingã®é©ç”¨ï¼ˆPhase 2bã‹ã‚‰ï¼‰"""
        
        print("   Target Encodingé©ç”¨ä¸­...")
        
        # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡ã®ç‰¹å®š
        categorical_features = []
        for col in train_df.columns:
            if col not in ['id', 'Personality'] and train_df[col].dtype == 'object':
                categorical_features.append(col)
        
        if not categorical_features:
            print("     ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡ãªã—ã€Target Encodingã‚¹ã‚­ãƒƒãƒ—")
            return train_df.copy(), test_df.copy()
        
        print(f"     å¯¾è±¡ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡: {categorical_features}")
        
        # æ•°å€¤åŒ–
        y_train = train_df[target_col].map({'Extrovert': 1, 'Introvert': 0})
        
        train_encoded = train_df.copy()
        test_encoded = test_df.copy()
        
        # CVå†…ã§ã®Target Encoding
        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=self.random_state)
        
        for feature in categorical_features:
            print(f"       {feature}ã®Target Encoding...")
            
            # CVå†…ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
            encoded_train = np.zeros(len(train_df))
            
            for train_idx, valid_idx in cv.split(train_df, y_train):
                # Train foldã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰è¾æ›¸ä½œæˆ
                train_fold_feature = train_df.iloc[train_idx][feature]
                train_fold_target = y_train.iloc[train_idx]
                
                # ã‚«ãƒ†ã‚´ãƒªåˆ¥å¹³å‡è¨ˆç®—
                encoding_dict = train_fold_feature.groupby(train_fold_feature).apply(
                    lambda x: train_fold_target.iloc[x.index].mean()
                ).to_dict()
                
                global_mean = train_fold_target.mean()
                
                # Valid foldã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰é©ç”¨
                valid_feature = train_df.iloc[valid_idx][feature]
                encoded_valid = valid_feature.map(encoding_dict).fillna(global_mean)
                encoded_train[valid_idx] = encoded_valid
            
            # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
            train_encoded[f'{feature}_target_encoded'] = encoded_train
            
            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”¨ã®å…¨ä½“ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰è¾æ›¸ä½œæˆ
            full_encoding_dict = train_df[feature].groupby(train_df[feature]).apply(
                lambda x: y_train.iloc[x.index].mean()
            ).to_dict()
            
            test_encoded[f'{feature}_target_encoded'] = test_df[feature].map(full_encoding_dict).fillna(y_train.mean())
        
        print(f"     Target Encodingç‰¹å¾´é‡è¿½åŠ æ•°: {len(categorical_features)}å€‹")
        return train_encoded, test_encoded
    
    def create_statistical_features(self, df):
        """çµ±è¨ˆçš„ç‰¹å¾´é‡ã®ä½œæˆ"""
        
        print("   çµ±è¨ˆçš„ç‰¹å¾´é‡ä½œæˆä¸­...")
        
        df_processed = df.copy()
        
        # æ•°å€¤ç‰¹å¾´é‡ã®çµ±è¨ˆ
        numeric_cols = []
        for col in df_processed.columns:
            if col not in ['id', 'Personality'] and pd.api.types.is_numeric_dtype(df_processed[col]):
                numeric_cols.append(col)
        
        if len(numeric_cols) > 1:
            numeric_data = df_processed[numeric_cols]
            
            # ç‰¹å¾´é‡çµ±è¨ˆ
            df_processed['feature_mean'] = numeric_data.mean(axis=1)
            df_processed['feature_std'] = numeric_data.std(axis=1)
            df_processed['feature_max'] = numeric_data.max(axis=1)
            df_processed['feature_min'] = numeric_data.min(axis=1)
            
            print(f"     çµ±è¨ˆçš„ç‰¹å¾´é‡è¿½åŠ æ•°: 4å€‹")
        else:
            print("     æ•°å€¤ç‰¹å¾´é‡ä¸è¶³ã€çµ±è¨ˆçš„ç‰¹å¾´é‡ã‚¹ã‚­ãƒƒãƒ—")
        
        return df_processed
    
    def create_hybrid_features(self, train_df, test_df):
        """çµ±åˆç‰¹å¾´é‡ä½œæˆãƒ¡ã‚¤ãƒ³é–¢æ•°"""
        
        print("=== çµ±åˆç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å®Ÿè¡Œ ===")
        print(f"å…ƒãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ - è¨“ç·´: {train_df.shape}, ãƒ†ã‚¹ãƒˆ: {test_df.shape}")
        
        # 1. å¿ƒç†å­¦ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹å¾´é‡
        train_psych = self.create_psychological_features(train_df)
        test_psych = self.create_psychological_features(test_df)
        
        # 2. Target Encoding
        train_encoded, test_encoded = self.apply_target_encoding(train_psych, test_psych)
        
        # 3. çµ±è¨ˆçš„ç‰¹å¾´é‡
        train_final = self.create_statistical_features(train_encoded)
        test_final = self.create_statistical_features(test_encoded)
        
        print(f"æœ€çµ‚ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ - è¨“ç·´: {train_final.shape}, ãƒ†ã‚¹ãƒˆ: {test_final.shape}")
        print(f"ç‰¹å¾´é‡å¢—åŠ æ•°: {train_final.shape[1] - train_df.shape[1]}å€‹")
        
        return train_final, test_final

def create_pseudo_labeled_data(train_df, confidence_threshold=0.85):
    """æ“¬ä¼¼ãƒ©ãƒ™ãƒªãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆï¼ˆãƒ•ã‚§ãƒ¼ã‚º2ã‹ã‚‰ï¼‰"""
    
    print("=== æ“¬ä¼¼ãƒ©ãƒ™ãƒªãƒ³ã‚°å®Ÿè¡Œ ===")
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    test_data = pd.read_csv('/Users/osawa/kaggle/playground-series-s5e7/data/raw/test.csv')
    
    # ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢é©ç”¨
    feature_engineer = HybridFeatureEngineer()
    train_features, test_features = feature_engineer.create_hybrid_features(train_df, test_data)
    
    # å‰å‡¦ç†
    feature_cols = [col for col in train_features.columns if col not in ['id', 'Personality']]
    
    # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
    X_train = train_features[feature_cols].copy()
    X_test = test_features[feature_cols].copy()
    
    for col in X_train.columns:
        if X_train[col].dtype == 'object':
            le = LabelEncoder()
            combined = pd.concat([X_train[col], X_test[col]]).astype(str)
            le.fit(combined)
            X_train[col] = le.transform(X_train[col].astype(str))
            X_test[col] = le.transform(X_test[col].astype(str))
    
    X_train = X_train.fillna(0).values
    X_test = X_test.fillna(0).values
    y_train = train_features['Personality'].map({'Extrovert': 1, 'Introvert': 0}).values
    
    # æ“¬ä¼¼ãƒ©ãƒ™ãƒ«ç”Ÿæˆç”¨ãƒ¢ãƒ‡ãƒ«
    pseudo_models = [
        lgb.LGBMClassifier(n_estimators=1000, random_state=42, verbosity=-1),
        xgb.XGBClassifier(n_estimators=1000, random_state=42, verbosity=0),
        CatBoostClassifier(iterations=1000, random_seed=42, verbose=False)
    ]
    
    # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬
    test_predictions = []
    
    for i, model in enumerate(pseudo_models):
        print(f"   ãƒ¢ãƒ‡ãƒ«{i+1}è¨“ç·´ä¸­...")
        model.fit(X_train, y_train)
        pred_proba = model.predict_proba(X_test)[:, 1]
        test_predictions.append(pred_proba)
    
    # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å¹³å‡
    ensemble_proba = np.mean(test_predictions, axis=0)
    
    # é«˜ä¿¡é ¼åº¦ã‚µãƒ³ãƒ—ãƒ«é¸æŠ
    confident_mask = (ensemble_proba >= confidence_threshold) | (ensemble_proba <= 1 - confidence_threshold)
    confident_indices = np.where(confident_mask)[0]
    
    if len(confident_indices) == 0:
        print("   é«˜ä¿¡é ¼åº¦ã‚µãƒ³ãƒ—ãƒ«ãªã—ã€å…ƒãƒ‡ãƒ¼ã‚¿ã®ã¿è¿”å´")
        return train_features
    
    # æ“¬ä¼¼ãƒ©ãƒ™ãƒ«ä½œæˆ
    pseudo_labels = (ensemble_proba[confident_indices] >= 0.5).astype(int)
    pseudo_labels_str = ['Extrovert' if label == 1 else 'Introvert' for label in pseudo_labels]
    
    # æ“¬ä¼¼ãƒ©ãƒ™ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
    pseudo_df = test_features.iloc[confident_indices].copy()
    pseudo_df['Personality'] = pseudo_labels_str
    pseudo_df['is_pseudo'] = True
    pseudo_df['confidence'] = np.maximum(ensemble_proba[confident_indices], 
                                       1 - ensemble_proba[confident_indices])
    
    # å…ƒãƒ‡ãƒ¼ã‚¿ã«ãƒ•ãƒ©ã‚°è¿½åŠ 
    train_features['is_pseudo'] = False
    train_features['confidence'] = 1.0
    
    # çµåˆ
    augmented_data = pd.concat([train_features, pseudo_df], ignore_index=True)
    
    print(f"   å…ƒãƒ‡ãƒ¼ã‚¿: {len(train_features)}ã‚µãƒ³ãƒ—ãƒ«")
    print(f"   æ“¬ä¼¼ãƒ©ãƒ™ãƒ«: {len(pseudo_df)}ã‚µãƒ³ãƒ—ãƒ«")
    print(f"   ç·è¨ˆ: {len(augmented_data)}ã‚µãƒ³ãƒ—ãƒ«")
    print(f"   æ‹¡å¼µç‡: {len(pseudo_df)/len(train_features)*100:.1f}%")
    
    return augmented_data

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    
    print("=== Phase 2b + ãƒ•ã‚§ãƒ¼ã‚º1+2 çµ±åˆå®Ÿè£… ===")
    
    # 1. å…ƒãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print("1. å…ƒãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
    train_data = pd.read_csv('/Users/osawa/kaggle/playground-series-s5e7/data/raw/train.csv')
    test_data = pd.read_csv('/Users/osawa/kaggle/playground-series-s5e7/data/raw/test.csv')
    
    print(f"   è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {train_data.shape}")
    print(f"   ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {test_data.shape}")
    
    # 2. çµ±åˆç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
    print("\\n2. çµ±åˆç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å®Ÿè¡Œä¸­...")
    feature_engineer = HybridFeatureEngineer()
    train_features, test_features = feature_engineer.create_hybrid_features(train_data, test_data)
    
    # 3. æ“¬ä¼¼ãƒ©ãƒ™ãƒªãƒ³ã‚°
    print("\\n3. æ“¬ä¼¼ãƒ©ãƒ™ãƒªãƒ³ã‚°å®Ÿè¡Œä¸­...")
    augmented_train = create_pseudo_labeled_data(train_features)
    
    # 4. ãƒ‡ãƒ¼ã‚¿ä¿å­˜
    print("\\n4. ãƒ‡ãƒ¼ã‚¿ä¿å­˜ä¸­...")
    
    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ä¿å­˜
    train_path = '/Users/osawa/kaggle/playground-series-s5e7/data/processed/hybrid_train_features.csv'
    augmented_train.to_csv(train_path, index=False)
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä¿å­˜
    test_path = '/Users/osawa/kaggle/playground-series-s5e7/data/processed/hybrid_test_features.csv'
    test_features.to_csv(test_path, index=False)
    
    print(f"âœ… çµ±åˆãƒ‡ãƒ¼ã‚¿ä½œæˆå®Œäº†!")
    print(f"   è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {augmented_train.shape} â†’ {train_path}")
    print(f"   ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {test_features.shape} â†’ {test_path}")
    
    # 5. çµ±è¨ˆã‚µãƒãƒªãƒ¼
    print(f"\\nğŸ“Š çµ±åˆå®Ÿè£…ã‚µãƒãƒªãƒ¼:")
    print(f"   å…ƒç‰¹å¾´é‡æ•°: {train_data.shape[1] - 2}")  # id, Personalityã‚’é™¤ã
    print(f"   çµ±åˆç‰¹å¾´é‡æ•°: {test_features.shape[1] - 1}")  # idã‚’é™¤ã
    print(f"   è¿½åŠ ç‰¹å¾´é‡æ•°: {test_features.shape[1] - train_data.shape[1] + 1}")
    print(f"   æ“¬ä¼¼ãƒ©ãƒ™ãƒ«æ‹¡å¼µç‡: {(len(augmented_train) - len(train_features))/len(train_features)*100:.1f}%")
    
    print(f"\\nğŸ¯ æœŸå¾…åŠ¹æœ:")
    print(f"   CVäºˆæƒ³: 0.975000+ (ãƒ•ã‚§ãƒ¼ã‚º1+2ã®0.974211 + Phase 2båŠ¹æœ)")
    print(f"   PBäºˆæƒ³: 0.976500+ (Phase 2bã®0.975708 + çµ±åˆåŠ¹æœ)")
    
    return augmented_train, test_features

if __name__ == "__main__":
    main()