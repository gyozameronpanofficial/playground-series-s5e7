"""
Phase 4 æ‹¡å¼µçµ±åˆç‰ˆæå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ

Phase 4æ‹¡å¼µæ‰‹æ³•ã§ã®æœ€çµ‚äºˆæ¸¬
CVçµæœ: 0.978715 Â± 0.000933 (æ­´ä»£æœ€é«˜)
PBçµæœ: [è¨˜è¼‰å¾…ã¡]

çµ±åˆè¦ç´ :
- å¿ƒç†å­¦ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹å¾´é‡ï¼ˆBig Fiveç†è«–ï¼‰
- Target EncodingåŠ¹æœ
- æ“¬ä¼¼ãƒ©ãƒ™ãƒªãƒ³ã‚°ï¼ˆ31.9%ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼‰
- é«˜åº¦æ¬ æå€¤å‡¦ç†ï¼ˆKNN + personality-awareï¼‰
- å¤–ã‚Œå€¤ç‰¹å¾´é‡ï¼ˆçµ±è¨ˆçš„é–¾å€¤ãƒ™ãƒ¼ã‚¹ï¼‰
- æˆ¦ç•¥çš„N-gramç‰¹å¾´é‡ï¼ˆå¿ƒç†å­¦çš„çµ„ã¿åˆã‚ã›ï¼‰
- ä¸¡å‘æ€§ç‰¹å¾´é‡ï¼ˆãƒãƒ©ãƒ³ã‚¹æŒ‡æ¨™ï¼‰
- sample_weightå¯¾å¿œï¼ˆä¿¡é ¼åº¦ãƒ™ãƒ¼ã‚¹é‡ã¿ä»˜ãå­¦ç¿’ï¼‰

Author: Osawa
Date: 2025-07-04
Purpose: Phase 4æ‹¡å¼µæ‰‹æ³•ã§ã®æœ€çµ‚æå‡º
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score
import lightgbm as lgb
import xgboost as xgb
from catboost import CatBoostClassifier
from sklearn.linear_model import LogisticRegression
import warnings
warnings.filterwarnings('ignore')

def create_phase4_individual_models():
    """å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«ä½œæˆï¼ˆsample_weightå¯¾å¿œï¼‰"""
    
    lgb_model = lgb.LGBMClassifier(
        objective='binary', num_leaves=31, learning_rate=0.02,
        n_estimators=1500, random_state=42, verbosity=-1
    )
    xgb_model = xgb.XGBClassifier(
        objective='binary:logistic', max_depth=6, learning_rate=0.02,
        n_estimators=1500, random_state=42, verbosity=0
    )
    cat_model = CatBoostClassifier(
        objective='Logloss', depth=6, learning_rate=0.02,
        iterations=1500, random_seed=42, verbose=False
    )
    lr_model = LogisticRegression(random_state=42, max_iter=1000)
    
    return lgb_model, xgb_model, cat_model, lr_model

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    
    print("=== Phase 4 æ‹¡å¼µçµ±åˆç‰ˆ æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ ===")
    print("CVçµæœ: 0.978715 Â± 0.000933 (æ­´ä»£æœ€é«˜)")
    print("ç‰¹å¾´é‡: 41å€‹ï¼ˆPhase 3ã®17å€‹ + æ‹¡å¼µ24å€‹ï¼‰")
    
    # 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print("\\n1. Phase 4çµ±åˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
    try:
        train_data = pd.read_csv('/Users/osawa/kaggle/playground-series-s5e7/data/processed/phase4_train_features.csv')
        test_data = pd.read_csv('/Users/osawa/kaggle/playground-series-s5e7/data/processed/phase4_test_features.csv')
        
        print(f"   çµ±åˆè¨“ç·´ãƒ‡ãƒ¼ã‚¿: {train_data.shape}")
        print(f"   çµ±åˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {test_data.shape}")
        
        # ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ
        original_samples = len(train_data[train_data['is_pseudo'] == False])
        pseudo_samples = len(train_data[train_data['is_pseudo'] == True])
        print(f"   å…ƒãƒ‡ãƒ¼ã‚¿: {original_samples}ã‚µãƒ³ãƒ—ãƒ«")
        print(f"   æ“¬ä¼¼ãƒ©ãƒ™ãƒ«: {pseudo_samples}ã‚µãƒ³ãƒ—ãƒ« ({pseudo_samples/original_samples*100:.1f}%)")
        
    except FileNotFoundError as e:
        print(f"   ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ - {e}")
        print("   å…ˆã«phase4_enhanced_integration.pyã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        raise
    
    # 2. ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
    print("\\n2. ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ä¸­...")
    
    # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†é›¢
    feature_cols = [col for col in train_data.columns 
                   if col not in ['id', 'Personality', 'is_pseudo', 'confidence']]
    
    # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
    train_processed = train_data[feature_cols].copy()
    test_processed = test_data[feature_cols].copy()
    
    label_encoders = {}
    categorical_cols = []
    
    for col in feature_cols:
        if train_processed[col].dtype == 'object':
            categorical_cols.append(col)
            le = LabelEncoder()
            
            # è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆçµåˆã—ã¦ãƒ•ã‚£ãƒƒãƒˆ
            combined_values = pd.concat([train_processed[col], test_processed[col]]).astype(str)
            le.fit(combined_values)
            
            # å¤‰æ›é©ç”¨
            train_processed[col] = le.transform(train_processed[col].astype(str))
            test_processed[col] = le.transform(test_processed[col].astype(str))
            
            label_encoders[col] = le
    
    # æ¬ æå€¤å‡¦ç†
    X_train = train_processed.fillna(0).values
    X_test = test_processed.fillna(0).values
    y_train = train_data['Personality'].map({'Extrovert': 1, 'Introvert': 0}).values
    test_ids = test_data['id'].values
    
    # ã‚µãƒ³ãƒ—ãƒ«é‡ã¿ï¼ˆæ“¬ä¼¼ãƒ©ãƒ™ãƒ«ã®ä¿¡é ¼åº¦ï¼‰
    sample_weight = train_data['confidence'].values
    
    print(f"   ä½¿ç”¨ç‰¹å¾´é‡æ•°: {X_train.shape[1]}å€‹")
    print(f"   è¨“ç·´ã‚µãƒ³ãƒ—ãƒ«æ•°: {X_train.shape[0]}ï¼ˆæ“¬ä¼¼ãƒ©ãƒ™ãƒ«è¾¼ã¿ï¼‰")
    print(f"   æ“¬ä¼¼ãƒ©ãƒ™ãƒ«æ•°: {pseudo_samples}å€‹")
    print(f"   ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ãŸç‰¹å¾´é‡æ•°: {len(label_encoders)}å€‹")
    
    # 3. ãƒ¢ãƒ‡ãƒ«è¨“ç·´ï¼ˆsample_weightå¯¾å¿œï¼‰
    print("\\n3. Phase 4æ‹¡å¼µãƒ¢ãƒ‡ãƒ«è¨“ç·´ä¸­ï¼ˆsample_weightå¯¾å¿œï¼‰...")
    
    # VotingClassifierã§ã¯sample_weightãŒé©åˆ‡ã«æ¸¡ã•ã‚Œãªã„ãŸã‚ã€å€‹åˆ¥å­¦ç¿’
    print("   å„ãƒ¢ãƒ‡ãƒ«ã‚’å€‹åˆ¥å­¦ç¿’ï¼ˆsample_weighté©ç”¨ï¼‰...")
    
    # å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«ä½œæˆ
    lgb_model, xgb_model, cat_model, lr_model = create_phase4_individual_models()
    
    # å„ãƒ¢ãƒ‡ãƒ«ã«sample_weightã‚’é©ç”¨ã—ã¦å­¦ç¿’
    print("   LightGBMå­¦ç¿’ä¸­...")
    lgb_model.fit(X_train, y_train, sample_weight=sample_weight)
    
    print("   XGBoostå­¦ç¿’ä¸­...")
    xgb_model.fit(X_train, y_train, sample_weight=sample_weight)
    
    print("   CatBoostå­¦ç¿’ä¸­...")
    cat_model.fit(X_train, y_train, sample_weight=sample_weight)
    
    print("   LogisticRegressionå­¦ç¿’ä¸­...")
    lr_model.fit(X_train, y_train, sample_weight=sample_weight)
    
    print("   âœ… å…¨ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Œäº†")
    
    # 4. äºˆæ¸¬å®Ÿè¡Œï¼ˆã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼‰
    print("\\n4. ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿äºˆæ¸¬ä¸­...")
    
    # å„ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬
    lgb_proba = lgb_model.predict_proba(X_test)[:, 1]
    xgb_proba = xgb_model.predict_proba(X_test)[:, 1]
    cat_proba = cat_model.predict_proba(X_test)[:, 1]
    lr_proba = lr_model.predict_proba(X_test)[:, 1]
    
    # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ï¼ˆã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ†ã‚£ãƒ³ã‚°ï¼‰
    test_proba = (lgb_proba + xgb_proba + cat_proba + lr_proba) / 4
    test_predictions = (test_proba > 0.5).astype(int)
    
    print("   âœ… ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬å®Œäº†")
    
    # 5. æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
    print("\\n5. æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆä¸­...")
    submission_df = pd.DataFrame({
        'id': test_ids,
        'Personality': ['Extrovert' if pred == 1 else 'Introvert' for pred in test_predictions]
    })
    
    # çµ±è¨ˆæƒ…å ±
    extrovert_count = np.sum(test_predictions == 1)
    introvert_count = np.sum(test_predictions == 0)
    avg_confidence = np.mean(np.maximum(test_proba, 1 - test_proba))
    
    print(f"\\nğŸ“Š äºˆæ¸¬çµ±è¨ˆ:")
    print(f"  Extrovert: {extrovert_count} ({extrovert_count/len(test_predictions)*100:.1f}%)")
    print(f"  Introvert: {introvert_count} ({introvert_count/len(test_predictions)*100:.1f}%)")
    print(f"  å¹³å‡ä¿¡é ¼åº¦: {avg_confidence:.4f}")
    
    # ä¿å­˜
    submission_path = '/Users/osawa/kaggle/playground-series-s5e7/submissions/phase4_enhanced_submission.csv'
    submission_df.to_csv(submission_path, index=False)
    
    print(f"\\nğŸ¯ Phase 4æ‹¡å¼µç‰ˆæå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå®Œäº†!")
    print(f"   ãƒ•ã‚¡ã‚¤ãƒ«: {submission_path}")
    print(f"   CVã‚¹ã‚³ã‚¢: 0.978715 Â± 0.000933 (æ­´ä»£æœ€é«˜)")
    print(f"   PBã‚¹ã‚³ã‚¢: [è¨˜è¼‰å¾…ã¡]")
    
    # å®Ÿè£…ã‚µãƒãƒªãƒ¼
    print(f"\\nğŸ† Phase 4æ‹¡å¼µå®Ÿè£…ã‚µãƒãƒªãƒ¼:")
    print(f"   Phase 3ç¶™æ‰¿: å¿ƒç†å­¦ç‰¹å¾´é‡ + Target Encoding + æ“¬ä¼¼ãƒ©ãƒ™ãƒªãƒ³ã‚°")
    print(f"   Phase 4æ–°è¦: é«˜åº¦æ¬ æå€¤å‡¦ç† + å¤–ã‚Œå€¤ç‰¹å¾´é‡ + N-gram + ä¸¡å‘æ€§")
    print(f"   ç·ç‰¹å¾´é‡æ•°: {X_train.shape[1]}å€‹")
    print(f"   æ“¬ä¼¼ãƒ©ãƒ™ãƒ«: {pseudo_samples}ã‚µãƒ³ãƒ—ãƒ« ({pseudo_samples/original_samples*100:.1f}%æ‹¡å¼µ)")
    print(f"   ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«: LightGBM + XGBoost + CatBoost + LogisticRegression")
    print(f"   é‡ã¿ä»˜ãå­¦ç¿’: æ“¬ä¼¼ãƒ©ãƒ™ãƒ«ä¿¡é ¼åº¦ãƒ™ãƒ¼ã‚¹")
    
    # Phase 4æ”¹å–„åŠ¹æœ
    print(f"\\nğŸ”§ Phase 4æ”¹å–„åŠ¹æœ:")
    phase3_cv = 0.976404
    phase4_cv = 0.978715
    improvement = phase4_cv - phase3_cv
    print(f"   Phase 3 CV: {phase3_cv:.6f}")
    print(f"   Phase 4 CV: {phase4_cv:.6f}")
    print(f"   æ”¹å–„åŠ¹æœ: +{improvement:.6f}")
    print(f"   æ”¹å–„ç‡: {improvement/phase3_cv*100:.3f}%")
    
    # æŠ€è¡“çš„å„ªä½æ€§
    print(f"\\nğŸ¯ æŠ€è¡“çš„å„ªä½æ€§:")
    print(f"   1. Target Encoded N-gram: æœ€é«˜åŠ¹æœã®ç‰¹å¾´é‡çµ„ã¿åˆã‚ã›")
    print(f"   2. KNN + personality-awareæ¬ æå€¤å‡¦ç†: ãƒ‡ãƒ¼ã‚¿å“è³ªå‘ä¸Š")
    print(f"   3. æˆ¦ç•¥çš„ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°: å¿ƒç†å­¦çŸ¥è­˜æ´»ç”¨")
    print(f"   4. sample_weightå®Œå…¨å¯¾å¿œ: æ“¬ä¼¼ãƒ©ãƒ™ãƒ«åŠ¹æœæœ€å¤§åŒ–")
    print(f"   5. CVå®‰å®šæ€§å‘ä¸Š: æ¨™æº–åå·®58%æ”¹å–„")
    
    # æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
    print(f"\\nğŸ“‹ æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã‚µãƒ³ãƒ—ãƒ«:")
    print(submission_df.head(10))
    
    return submission_df

if __name__ == "__main__":
    main()